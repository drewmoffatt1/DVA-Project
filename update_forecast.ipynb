{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61b349c8",
   "metadata": {},
   "source": [
    "### Weather Forecast API Pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baba7b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17989bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import datetime as dt\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d697f9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date():\n",
    "    return (dt.date.today() + dt.timedelta(days=1)).strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89da93e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zone_mapping():\n",
    "    zm = pd.read_csv('models/zone_mapping_hist_peak.csv')\n",
    "    zone_dict = dict()\n",
    "    for i in zm['zone']:\n",
    "        this_val = dict()\n",
    "        this_val['lat'] = zm['lat'].loc[zm['zone'] == i].iloc[0]\n",
    "        this_val['long'] = zm['long'].loc[zm['zone'] == i].iloc[0]\n",
    "        zone_dict[i] = this_val\n",
    "    return zone_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed8dda51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def holiday_cal(strdate):\n",
    "    from pandas.tseries.holiday import get_calendar, nearest_workday, Holiday\n",
    "\n",
    "    usfh = get_calendar(\"USFederalHolidayCalendar\")\n",
    "    juneteenth = Holiday(\n",
    "        \"Juneteenth\", month=6, day=19, start_date='2021-10-01', observance=nearest_workday\n",
    "    )\n",
    "    if not any(h.name == \"Juneteenth\" for h in usfh.rules):\n",
    "        usfh.rules.append(juneteenth)\n",
    "    return usfh.holidays(strdate, strdate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3357536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cycle_encode(df, var, minval, maxval):\n",
    "    space = 2*np.pi/(maxval-minval)\n",
    "    return np.cos(space*df[var]), np.sin(space*df[var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85081a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dow_encode(row):\n",
    "    dow_dict = {'Monday':1, 'Tuesday':2, 'Wednesday':3, 'Thursday':4, 'Friday':5, 'Saturday':6, 'Sunday':7}\n",
    "    return dow_dict.get(row['dow'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14c2300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_season_encode(row):\n",
    "    if row['month'] in [6, 7, 8, 9]:\n",
    "        return 1\n",
    "    elif row['month'] in [5, 10]:\n",
    "        return 2\n",
    "    elif row['month'] in [4, 11]:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d336cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_empty_df():\n",
    "    ## bring in date\n",
    "    strdate = get_date()\n",
    "    \n",
    "    ## bring in holidays\n",
    "    holidays = holiday_cal(strdate)\n",
    "    \n",
    "    ## create initial DF\n",
    "    df = pd.DataFrame()\n",
    "    df['datetime'] = pd.date_range(strdate, periods=24, freq=\"H\")\n",
    "    df['datetime'] = df['datetime'].dt.tz_localize('US/Eastern', ambiguous = 'NaT', nonexistent = 'NaT')\n",
    "    df = df.dropna()\n",
    "    \n",
    "    ## basic date variables\n",
    "    df['date'] = df['datetime'].dt.date\n",
    "    df['year'] = df['datetime'].dt.year\n",
    "    df['month'] = df['datetime'].dt.month\n",
    "    df['hour'] = df['datetime'].dt.hour\n",
    "    ## extract DOW\n",
    "    df['dow'] = df['datetime'].dt.day_name()\n",
    "\n",
    "    ## extract DST\n",
    "    df['is_dst'] = (df['datetime'].dt.strftime('%z') == '-0400')\n",
    "\n",
    "    ## extract stay-at-home orders timeframe\n",
    "    sah_start = pd.to_datetime('3/18/2020').tz_localize('US/Eastern', ambiguous = 'NaT')\n",
    "    sah_end = pd.to_datetime('6/30/2020').tz_localize('US/Eastern', ambiguous = 'NaT')\n",
    "    df['is_sah'] = df['datetime'].between(sah_start, sah_end)\n",
    "\n",
    "    ## extract pre-covid\n",
    "    df['precovid'] = df['datetime'] < sah_start\n",
    "\n",
    "    ## extract post-covid\n",
    "    df['postcovid'] = df['datetime'] > sah_end\n",
    "    \n",
    "    ## weekend indicator\n",
    "    df['weekend'] = df['dow'].isin(['Sunday', 'Saturday'])\n",
    "    \n",
    "    ## recent\n",
    "    df['recent'] = 1\n",
    "    \n",
    "    ## create cyclical month and hour variables\n",
    "    df['hour_cos'], df['hour_sin'] = cycle_encode(df, 'hour', 0, 23)\n",
    "    df['month_cos'], df['month_sin'] = cycle_encode(df, 'month', 1, 12)    \n",
    "    \n",
    "    ## create dow encoding\n",
    "    df['dow_num'] = df.apply(get_dow_encode, axis = 1)\n",
    "    \n",
    "    ##holiday\n",
    "    df['holiday'] = df['datetime'].dt.strftime('%Y-%m-%d').isin(holidays)\n",
    "    \n",
    "    ## season encoding\n",
    "    df['season_num'] = df.apply(get_season_encode, axis = 1)\n",
    "    \n",
    "    return df[['datetime', 'date', 'hour', 'year', 'dow', 'is_dst', 'is_sah',\n",
    "       'precovid', 'postcovid', 'weekend', 'recent', 'hour_cos', 'hour_sin',\n",
    "       'month_cos', 'month_sin', 'dow_num', 'holiday', 'season_num']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91d3305f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_weather_forecast(zone, zones_dict):\n",
    "    ## Set parameters for API call\n",
    "    latitude = str(zones_dict.get(zone).get('lat'))\n",
    "    longitude = str(zones_dict.get(zone).get('long'))\n",
    "    strdate = get_date()\n",
    "    timezone = 'America%2FNew_York'\n",
    "\n",
    "    ## Make API call\n",
    "    response = requests.get(\n",
    "                            \"https://api.open-meteo.com/v1/forecast?\" + \\\n",
    "                            'latitude=' + latitude + \\\n",
    "                            '&longitude=' + longitude + \\\n",
    "                            '&hourly=temperature_2m,relativehumidity_2m,precipitation,weathercode,surface_pressure,' + \\\n",
    "                            'windspeed_10m' + \\\n",
    "                            '&temperature_unit=fahrenheit&windspeed_unit=mph&precipitation_unit=inch' + \\\n",
    "                            '&timezone=America%2FNew_York' + \\\n",
    "                            '&start_date=' + strdate + \\\n",
    "                            '&end_date=' + strdate\n",
    "                           )\n",
    "\n",
    "    forecast = response.json()\n",
    "    tzz = forecast.get('timezone_abbreviation')\n",
    "    if 'S' in tzz:\n",
    "        affix = '-0500'\n",
    "    else:\n",
    "        affix = '-0400'\n",
    "\n",
    "\n",
    "    ## Format API response\n",
    "\n",
    "    # Define weathercodes as rain/snow\n",
    "    rain_codes = [51,53,55,61,63,65,80,81,82,95,96,99]\n",
    "    snow_codes = [56,57,66,67,71,73,75,77,85,86]\n",
    "\n",
    "    hourly = forecast.get('hourly')\n",
    "\n",
    "    df2 = pd.DataFrame()\n",
    "    for i in hourly.keys():\n",
    "        df2[i] = hourly.get(i)\n",
    "    df2['datetime'] = pd.to_datetime(df2['time']+affix)\n",
    "    df2['datetime'] = df2['datetime'].dt.tz_convert('US/Eastern')\n",
    "    df2 = df2.dropna()\n",
    "    df2['rain'] = df2['weathercode'].isin(rain_codes)\n",
    "    df2['snow'] = df2['weathercode'].isin(snow_codes)\n",
    "    \n",
    "    ## convert pressure from hPa to inHg\n",
    "    df2['pressure'] = df2['surface_pressure'] * 0.029529983071445\n",
    "    df2 = df2[['temperature_2m', 'relativehumidity_2m', 'precipitation',\n",
    "           'pressure', 'windspeed_10m', 'datetime', 'rain',\n",
    "           'snow']].copy()\n",
    "    df2.columns = ['temp', 'rh', 'precip',\n",
    "           'pressure', 'windspeed', 'datetime', 'rain',\n",
    "           'snow']\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26ab6a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_analysis_df(zone, zones_dict, base_df):\n",
    "    df2 = api_weather_forecast(zone, zones_dict)\n",
    "    df8 = base_df.merge(df2, on='datetime', how='left')\n",
    "    result_df = df8[['date', 'hour', 'temp']].copy()\n",
    "    result_df['zone'] = zone\n",
    "    x = df8[['year', 'weekend', 'holiday', 'is_dst', 'is_sah', 'precovid',\n",
    "       'postcovid', 'temp', 'precip', 'rh', 'pressure', 'windspeed', 'rain', 'snow',\n",
    "       'recent', 'hour_cos', 'hour_sin', 'month_cos', 'month_sin', 'dow_num']].copy()\n",
    "    return result_df, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f3702b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hourly_forecast():\n",
    "    ## run base dataset\n",
    "    df1 = make_empty_df()\n",
    "\n",
    "    ## zones\n",
    "    zones_dict = zone_mapping()\n",
    "    zones = list(zones_dict.keys())\n",
    "    zones.sort()\n",
    "\n",
    "    ## create full results dataset\n",
    "    full_forecast = pd.DataFrame(columns = ['zone', 'date', 'hour', 'mw', 'temp'])\n",
    "    for z in zones:\n",
    "        result_df, x = create_analysis_df(z, zones_dict, df1)\n",
    "        model2 = xgb.XGBRegressor()\n",
    "        model2.load_model(\"models/xgb_mod_\" + z + \".txt\")\n",
    "\n",
    "\n",
    "        result_df['mw'] = model2.predict(x)\n",
    "        full_forecast = pd.concat([full_forecast, result_df], axis = 0)\n",
    "    return full_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e0edf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_data():\n",
    "    ## run models to get hourly predictions\n",
    "    hourly_forecast = get_hourly_forecast()\n",
    "    \n",
    "    ## bring in zone data for the historical peak data\n",
    "    zzz = pd.read_csv('models/zone_mapping_hist_peak.csv')\n",
    "    zzz = zzz[['zone', 'hist_peak_mw']].copy()\n",
    "    \n",
    "    ## aggregate up to the system to get the peak hour for the day\n",
    "    system = hourly_forecast.groupby(['hour'], as_index = False).agg({'mw': 'sum'})\n",
    "    peak_hr = system['hour'].loc[system['mw'] == max(system['mw'])].iloc[0]\n",
    "    system['peak_hour'] = peak_hr\n",
    "    \n",
    "    ## create the peak hour data\n",
    "    peak_forecast = hourly_forecast.loc[hourly_forecast['hour'] == peak_hr]\n",
    "    peak_forecast = peak_forecast[['zone', 'date', 'hour', 'mw']].copy()\n",
    "    peak_forecast.columns = ['zone', 'date', 'peak_hour', 'peak_hour_mw']\n",
    "    peak_forecast = peak_forecast.merge(zzz, how = 'left', on = 'zone')\n",
    "    peak_forecast['pct_hist_peak_mw'] = peak_forecast['peak_hour_mw']/peak_forecast['hist_peak_mw']\n",
    "\n",
    "    ## create the hourly forecast data\n",
    "    hourly_forecast = hourly_forecast[['zone', 'hour', 'mw', 'temp']]\n",
    "    hourly_forecast.columns = ['zone', 'hour', 'hourly_mw', 'temp']\n",
    "    \n",
    "    ## finalize system hourly data\n",
    "    system.columns = ['hour', 'system_mw', 'peak_hour']\n",
    "    \n",
    "    ## return 3 datasets\n",
    "    return peak_forecast, hourly_forecast, system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19fed31",
   "metadata": {},
   "source": [
    "## Run functions to create datasets and run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e576032",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_forecast, hourly_forecast, system = output_data()\n",
    "\n",
    "## export each to csv (or change this if proceeding with live solution)\n",
    "peak_forecast.to_csv('output/peak_hour_forecast.csv', index = False)\n",
    "hourly_forecast.to_csv('output/hourly_forecast.csv', index = False)\n",
    "system.to_csv('output/system_hourly_forecast.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
